% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/create_bigrams.R
\name{create_bigrams}
\alias{create_bigrams}
\title{Identify and combine the most frequent, non-stopword bigrams in a text column.}
\usage{
create_bigrams(
  data,
  text_col,
  n_bigrams = 10,
  stopwords_language = "en",
  custom_stopwords = NULL
)
}
\arguments{
\item{data}{A data frame (or tibble) containing the text data.}

\item{text_col}{The unquoted column name in \code{data} that contains the
text strings (e.g., \code{text} or \code{document}). This uses tidy-selection
syntax (\code{\{\{...\}\}}).}

\item{n_bigrams}{An integer specifying the number of top bigrams to identify
and combine into single tokens. Defaults to \code{10}.}

\item{stopwords_language}{A character string specifying the language for
the default stop words, as supported by the \code{stopwords} package (e.g., \code{"en"}, \code{"de"}).
Defaults to \code{"en"}. Use \code{NULL} if you only want to use \code{custom_stopwords}.}

\item{custom_stopwords}{A character vector of additional stop words to
exclude from bigram formation. Defaults to \code{NULL}.}
}
\value{
A data frame (tibble) with the original data plus a new column named
\code{text} containing the modified text with the most frequent, valid bigrams
combined. The original text column is overwritten with the new, lowercased,
and combined text. If no valid bigrams are found after filtering, the original
data frame is returned with a warning, and a column named \code{text_combined}
is created instead.
}
\description{
This function analyzes a text column in a data frame, identifies the top \code{n_bigrams}
most frequent bigrams (two consecutive words), filters out those containing
common stop words, and replaces the identified bigrams in the text with a single
token where the words are joined by an underscore (e.g., "new york" becomes "new_york").
The input text is converted to lowercase prior to processing.
}
\details{
This function is a key preprocessing step for embedding models as it helps them
capture multi-word concepts (like "data science") as single, cohesive tokens,
which improves the quality of the resulting vectors.

\strong{Internal Workflow:}
\enumerate{
\item Text is tokenized into bigrams.
\item The bigrams are split, and any pair containing a stop word (either default or custom)
is removed via \code{anti_join}.
\item The remaining bigrams are combined with an underscore and used as a lookup
vector for replacement using \code{stringr::str_replace_all()}.
}
}
\examples{
\dontrun{
# Assuming 'my_corpus' is a tibble with a column named 'document_content'
my_corpus <- tibble::tibble(
  id = 1:2,
  document_content = c(
    "natural language processing is great fun",
    "i love natural language processing in r"
  )
)

# Combine the top 5 bigrams, excluding default English stopwords
result <- create_bigrams(
  data = my_corpus,
  text_col = document_content,
  n_bigrams = 5
)

# Expected output column 'text' will contain "natural_language" and/or "language_processing"
print(result$text)
}
}
